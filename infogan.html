<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Prabowo Setiawan - About Me</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<style>
		h1 {
			font-size: 300%;
		}
	</style>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Data Science</strong> Portfolio</a>
									<ul class="icons">
										<li><a href="https://www.linkedin.com/in/prabowo-setiawan/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
										<li><a href="https://medium.com/@prabowoas1002/" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
										<li><a href="mailto:prabowo.ast@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
									</ul>
								</header>
							<!-- Content -->
								<section>
									<header class="main">
										<h1>InfoGAN - Study on MNIST Dataset</h1>
									</header>

									<h2>Project Description</h2>
									<p>
										The project aims to reconstruct the Information Maximizing Generative Adversarial Network (InfoGAN) to learn the network capabilities in disentangle complex representations. The networks consist of a generator, discriminator and auxiliary. The generator produces fake image given probability distribution as noise, two continuous latent code and a single categorical code. There are 74 latent codes in total, 62 from noise, 2 from continuous code and 10 from categorical code (since the image classification relates to digits from 0 to 9). <br></br>

                                        The discriminator selectively chooses images that are real, from training dataset, and fake, from generator. The two networks play a minimax game in which that the generator is trying to fool the discriminator to produce fake images to be labelled real. An additional network is introduced, an auxiliary model, that can provide mutual information loss (minimizing the probability density of continuous codes and binary crossentropy of categorical code). This model is trained and share its loss values with both the generator and discriminator. It is hoped that this network architecture can generate valid images while obtaining specific meaning from the latent codes. <br></br>

                                        This project is inspired by <a href='https://arxiv.org/abs/1606.03657'>InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets</a>.
                                    </p>
									<h2>Project Result</h2>
                                    <p>
                                        The result of the training can be shown in several ways. The first aspect is the network losses. Both the generator and auxiliary's losses are decreasing in a stable fashion. This is ideal since it is preferred to have lower loss function for the generator to produce 'real' image and for the auxiliary model to produce less mutual info loss. Yet we can see that the discriminator's loss is increasing. Since the discriminator and the generator is playing a minmax game, it is most likely that the decreasing generator loss affects the increasing discriminator loss. <br></br>

                                        <span class="image mid"><img src="images/network_losses.png" alt="" /></span> <br></br>

                                        The following figure showcases the number of epochs and the quality of images generated by the generator model. <br></br>

                                        <span class="image mid"><img src="images/image_generated_epoch_99.png" alt="" /></span> <br></br>

                                        Now let's take a look at the plots for varying c1 and c2, as well as the varied categorical code. <br></br>

                                        <span class="image left"><img src="images/generated_vary_c1.png" alt="" /></span> 
                                        <span class="image right"><img src="images/generated_vary_c2.png" alt="" /></span>

                                        From the 2 plots above, the categorical code is varied across the column. This can be considered a success that we see different digit in every row. Although it is obvious that the categorical code is learned unsupervised by the model, therefore code 1 does not necessarily correlate to number 1. Also another note, this categorical code isn't perfect in a sense that some of the digits are misclassified. <br></br>

                                        As for the continuous code, c2 seems to control the thickness of the digit although it is somewhat responsible in the rotation of the image. But this is not as obvious as we can see from c1. Therefore, this can be a point of improvement as to create a network / preprocess the data prior to training so that the c1 and c2 can learn the latent representation of the images better.
                                    </p>

									<h2>Conclusion & Future Improvement</h2>

									<p>
										From the project results, it can be concluded that the model performs decently. The categorical code, although not perfect, like any other classifiers out there, is able to categorize the digits from MNIST dataset. Not to mention that the c1 and c2 continuous codes are able to capture the thickness and rotation aspects of the image. A prospect improvement within the model can be the implementation of optimizers, learning rates and batch size as well as the epoch training numbers. In other words, hyperparameters can play a huge factor in improving the model. Another potential improvement can be applied on the network's architecture. The different kind of layers, activation functions and batch normalizations can also be altered to further increase the model's performance.
									</p>
									
									<h3>Links</h3>
									<a href="https://github.com/prabowst/infogan" class="icon brands fa-github"><span class="label">Github</span><strong> Github Repository</strong></a>
									<!--hr class="major" />

									<h2>Magna etiam veroeros</h2>
									<p>Content</p>
									<p>Content</p-->
								</section>
						</div>
					</div>

				<!-- Sidebar -->
				<div id="sidebar">
					<div class="inner">
						<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="index.html">Home</a></li>
									<li><a href="about_me.html">About Me</a></li>
									<li><a href="resume.html">Resume</a></li>
									<li>
										<span class="opener">Projects</span>
										<ul>
											<li><a href="starbucks.html">Starbucks Customer Behavior - Rewards App</a></li>
											<li><a href="infogan.html">InfoGAN - Study on MNIST Dataset</a></li>
										</ul>
									</li>
								</ul>
							</nav>

						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">&copy; HTML5 UP. All rights reserved. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
							</footer>

					</div>
				</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>